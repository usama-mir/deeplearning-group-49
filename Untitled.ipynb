{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset \n",
    "import os\n",
    "from torchvision.transforms import *\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "import logging\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.functional import dice as pt_dice_score\n",
    "import random\n",
    "from PIL.ImageFilter import GaussianBlur\n",
    "import math\n",
    "from numpy import load\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import segmentation_models_pytorch.utils.losses as smpLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_paths = r\"C:/Users/tala1/Skrivebord/deeplearning/deeplearning-final-project/txts/\"\n",
    "\n",
    "def get_data_paths(files, data_target):\n",
    "    data_paths = []\n",
    "    for f in files:\n",
    "        for t in data_target:\n",
    "            if (f[:-4] == t[:-4]):\n",
    "                data_paths.append(f)\n",
    "    return data_paths\n",
    "\n",
    "\n",
    "def get_data_without_folder(files, folder):\n",
    "    data = []\n",
    "    for f in files:\n",
    "        if f not in folder:\n",
    "            data.append(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_augmented(data_no_test, test_data):\n",
    "    test_augmented = []\n",
    "    for f in data_no_test:\n",
    "        for t in test_data:\n",
    "            if t[:-4]+\"-aug\" == f[:-6]:\n",
    "                test_augmented.append(f)\n",
    "    return test_augmented\n",
    "\n",
    "\n",
    "def get_specific_data(dataset, data_type):\n",
    "    dataset_na = []\n",
    "    for f in dataset:\n",
    "        if data_type in f:\n",
    "            dataset_na.append(f)\n",
    "    return dataset_na\n",
    "\n",
    "\n",
    "def get_gan_images(dataset):\n",
    "    gan_file = open(txt_paths+\"cycle_gan_files.txt\", \"r\")\n",
    "    gan_data_jpg = gan_file.read().split(\"\\n\")\n",
    "    gan = get_data_paths(dataset, gan_data_jpg)\n",
    "    return gan\n",
    "\n",
    "\n",
    "class CarDataset(Dataset):\n",
    "    def __init__(self, imgs_dir, seed=42, num_opel=-1, num_door=-1,\n",
    "                 num_deloitte_aug=-1, num_gan=-1, num_primary_multiple=1, augmentation=None, \n",
    "                 test=False, predictor=None, bg_manager=None, grayscale=False):\n",
    "        self.imgs_dir = imgs_dir\n",
    "        self.augmentation = augmentation\n",
    "        self.predictor = predictor\n",
    "        self.bg_manager = bg_manager\n",
    "        self.grayscale = grayscale\n",
    "\n",
    "        raw_ids = os.listdir(imgs_dir)\n",
    "\n",
    "        random.seed(seed)\n",
    "        random.shuffle(raw_ids)\n",
    "\n",
    "        self.ids = []\n",
    "\n",
    "        if (test == False):\n",
    "            opel = get_specific_data(raw_ids, 'OPEL')\n",
    "            if (num_opel == -1):\n",
    "                self.ids = self.ids + opel\n",
    "            else:\n",
    "                assert(len(opel) >= num_opel)\n",
    "                random.seed(seed)\n",
    "                sample_opel = random.sample(opel, num_opel)\n",
    "                self.ids = self.ids + sample_opel\n",
    "\n",
    "            door = get_specific_data(raw_ids, 'DOOR')\n",
    "            if (num_door == -1):\n",
    "                self.ids = self.ids + door\n",
    "            else:\n",
    "                assert(len(door) >= num_door)\n",
    "                random.seed(seed)\n",
    "                sample_door = random.sample(door, num_door)\n",
    "                self.ids = self.ids + sample_door\n",
    "\n",
    "            aug = get_specific_data(raw_ids, '-aug')\n",
    "            if (num_deloitte_aug == -1):\n",
    "                self.ids = self.ids + aug\n",
    "            else:\n",
    "                assert(len(aug) >= num_deloitte_aug)\n",
    "                random.seed(seed)\n",
    "                sample_aug = random.sample(aug, num_deloitte_aug)\n",
    "                self.ids = self.ids + sample_aug\n",
    "\n",
    "            gan = get_gan_images(raw_ids)\n",
    "            if (num_gan == -1):\n",
    "                self.ids = self.ids + gan\n",
    "            else:\n",
    "                assert(len(gan) >= num_gan)\n",
    "                random.seed(seed)\n",
    "                sample_gan = random.sample(gan, num_gan)\n",
    "                self.ids = self.ids + sample_gan\n",
    "\n",
    "            primary_images = []\n",
    "            for f in raw_ids:\n",
    "                if ((f not in aug) and (f not in gan) and (f not in door) and (f not in opel)):\n",
    "                    primary_images.append(f)\n",
    "            for i in range(num_primary_multiple):\n",
    "                self.ids = self.ids + primary_images\n",
    "        else:\n",
    "            self.ids = raw_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        idx = self.ids[i]\n",
    "\n",
    "        np_obj = glob(self.imgs_dir + idx)\n",
    "\n",
    "        data = load(np_obj[0])\n",
    "\n",
    "        img = data[0:3]\n",
    "        # We try to remove the background\n",
    "        if (self.predictor != None):\n",
    "            image_bg = self.bg_manager.get_image(np_obj[0])\n",
    "            if (image_bg == 'empty'):\n",
    "                img_no_bg = self.bg_manager.get_img_no_bg(self.predictor, np.dstack(img))\n",
    "                if (img_no_bg != 'empty'):\n",
    "                    self.bg_manager.add_image(np_obj[0],img_no_bg)\n",
    "                else: \n",
    "                    self.bg_manager.add_image(np_obj[0],'empty')\n",
    "            else: \n",
    "                img_no_bg = image_bg\n",
    "            if (img_no_bg != 'empty'):\n",
    "                img = torch.from_numpy(img_no_bg).type(\n",
    "                    torch.FloatTensor)  # numpy -> torch\n",
    "                # The predictor takes H,W,C so we make it C,H,W again\n",
    "                img = img.permute(2, 0, 1)\n",
    "            else:\n",
    "                # print(\"------- COULD NOT REMOVE BACKGROUND OF IMAGE: ---------\")\n",
    "                # print(np_obj)\n",
    "                # print(\"-------------------------------------------------------\")\n",
    "                img = torch.from_numpy(img).type(\n",
    "                    torch.FloatTensor)  # numpy -> torch\n",
    "        else:\n",
    "            img = torch.from_numpy(img).type(\n",
    "                torch.FloatTensor)  # numpy -> torch\n",
    "\n",
    "        mask = data[-1]\n",
    "        mask = torch.from_numpy(mask).type(torch.FloatTensor)  # numpy -> torch\n",
    "        mask = torch.nn.functional.one_hot(\n",
    "            mask.to(torch.int64), 9)  # We one-hot-encode the mask\n",
    "        mask = mask.permute(2, 0, 1)  # (256,256,9) -> (9,256,256)\n",
    "\n",
    "        if (self.augmentation != None):\n",
    "            # Choose a numpy seed and ensure that transforms use it\n",
    "            seed = np.random.randint(2147483647)\n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            img = self.augmentation(img)\n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            mask = self.augmentation(mask)\n",
    "        \n",
    "        if (self.grayscale == True):\n",
    "            img = T.Grayscale()(img)\n",
    "\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "save_path = r\"C:/Users/tala1/Skrivebord/deeplearning/deeplearning-final-project/filtered_data/\"\n",
    "data_path = r\"C:/Users/tala1/Downloads/carseg_data/carseg_data/clean_data_test/\"\n",
    "files = os.listdir(data_path)\n",
    "\n",
    "for file in files:\n",
    "    path_d = data_path + file\n",
    "    img_array = np.load(path_d)\n",
    "    rgb_dims = img_array[0:3]\n",
    "    rgb_dims[0,:,:]=(rgb_dims[0,:,:]+0.485/0.229-0.485)/0.229\n",
    "    rgb_dims[1,:,:]=(rgb_dims[1,:,:]+0.456/0.224-0.456)/0.224\n",
    "    rgb_dims[2,:,:]=(rgb_dims[2,:,:]+0.406/0.225-0.406)/0.225\n",
    "    #print(img_array[3])\n",
    "    mask = img_array[3]\n",
    "    combined_data = np.append(rgb_dims, [mask], axis=0)\n",
    "    path_s = save_path + file\n",
    "    np.save(path_s, combined_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data in test/valid/train  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train prim len: 8 - val prim len: 1\n",
      "train aug len: 0 - val aug len: 0\n"
     ]
    }
   ],
   "source": [
    "def get_data_paths(files, data_target):\n",
    "    data_paths = []\n",
    "    for f in files:\n",
    "        for t in data_target:\n",
    "            if (f[:-4] == t[:-4]):\n",
    "                data_paths.append(f)\n",
    "    return data_paths\n",
    "\n",
    "\n",
    "def get_data_without_folder(files, folder):\n",
    "    data = []\n",
    "    for f in files:\n",
    "        if f not in folder:\n",
    "            data.append(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_augmented(data_no_test, test_data):\n",
    "    test_augmented = []\n",
    "    for f in data_no_test:\n",
    "        for t in test_data:\n",
    "            if t[:-4]+\"-aug\" == f[:-6]:\n",
    "                test_augmented.append(f)\n",
    "    return test_augmented\n",
    "\n",
    "\n",
    "def get_specific_data(dataset, data_type):\n",
    "    dataset_na = []\n",
    "    for f in dataset:\n",
    "        if data_type in f:\n",
    "            dataset_na.append(f)\n",
    "    return dataset_na\n",
    "\n",
    "\n",
    "def save_files(data_path, save_path, arr):\n",
    "    for i in arr:\n",
    "        path = data_path + i\n",
    "        data = np.load(path)\n",
    "        new_path = save_path + i\n",
    "        np.save(new_path, data)\n",
    "\n",
    "\n",
    "# The folder where you run this script\n",
    "txt_paths = r\"C:/Users/tala1/Skrivebord/deeplearning/deeplearning-final-project/txts/\"\n",
    "data_path = r\"C:/Users/tala1/Skrivebord/deeplearning/deeplearning-final-project/filtered_data/\"\n",
    "save_path =r\"C:/Users/tala1/Skrivebord/deeplearning/deeplearning-final-project/splitted_data/\"\n",
    "files = os.listdir(data_path)\n",
    "\n",
    "# First we get the 30 test images given by martin, and remove the augmented versions of them\n",
    "test_file = open(txt_paths+\"test_data.txt\", \"r\")\n",
    "test_data_jpg = test_file.read().split(\"\\n\")\n",
    "\n",
    "test = get_data_paths(files, test_data_jpg)\n",
    "data_no_test = get_data_without_folder(files, test)\n",
    "test_augmented = get_augmented(data_no_test, test)\n",
    "training_data = get_data_without_folder(data_no_test, test_augmented)\n",
    "\n",
    "# We then get all the gan images and save them\n",
    "gan_file = open(txt_paths+\"cycle_gan_files.txt\", \"r\")\n",
    "gan_data_jpg = gan_file.read().split(\"\\n\")\n",
    "gan = get_data_paths(files, gan_data_jpg)\n",
    "training_no_gan = get_data_without_folder(training_data, gan)\n",
    "\n",
    "# We get all the opel images and save them\n",
    "opel = get_specific_data(training_no_gan, 'OPEL')\n",
    "training_no_opel = get_data_without_folder(training_no_gan, opel)\n",
    "\n",
    "# We get all the door images and save them\n",
    "door = get_specific_data(training_no_opel, 'DOOR')\n",
    "training_no_door = get_data_without_folder(training_no_opel, door)\n",
    "\n",
    "# We get all the augmented images and save them\n",
    "aug = get_specific_data(training_no_door, \"-aug\")\n",
    "training_primary = get_data_without_folder(training_no_door, aug)\n",
    "\n",
    "##################################################################################\n",
    "# Now we split each of the different data kinds up in 80/20 train and validation #\n",
    "seed_int = 32  # set seed to get same splits everytime\n",
    "\n",
    "random.seed(seed_int)\n",
    "train_primary = random.sample(\n",
    "    training_primary, math.ceil(len(training_primary)*0.80))\n",
    "val_primary = [i for i in training_primary if i not in train_primary]\n",
    "print(\"train prim len:\", len(train_primary),\n",
    "      \"- val prim len:\", len(val_primary))\n",
    "\n",
    "# We get all the augmented of our primary data and add them in train and aug\n",
    "train_aug = get_augmented(aug, train_primary)\n",
    "val_aug = get_augmented(aug, val_primary)\n",
    "print(\"train aug len:\", len(train_aug), \"- val aug len:\", len(val_aug))\n",
    "\n",
    "random.seed(seed_int)\n",
    "train_opel = random.sample(opel, math.ceil(len(opel)*0.80))\n",
    "val_opel = [i for i in opel if i not in train_opel]\n",
    "\n",
    "random.seed(seed_int)\n",
    "train_door = random.sample(door, math.ceil(len(door)*0.80))\n",
    "val_door = [i for i in door if i not in train_door]\n",
    "\n",
    "random.seed(seed_int)\n",
    "train_gan = random.sample(gan, math.ceil(len(gan)*0.80))\n",
    "val_gan = [i for i in gan if i not in train_gan]\n",
    "\n",
    "# And finally we now have a completely fair split of 80/20 of each kind\n",
    "validation = val_gan+val_door+val_opel+val_aug+val_primary\n",
    "train = train_gan+train_door+train_opel+train_aug+train_primary\n",
    "\n",
    "# Unit tests to ensure that the 3 are completely split up\n",
    "for i in train:\n",
    "    assert(i not in validation)\n",
    "    assert(i not in test)\n",
    "\n",
    "for i in validation:\n",
    "    assert(i not in test)\n",
    "\n",
    "# Save images\n",
    "save_files(data_path, save_path+\"test/\", test)\n",
    "save_files(data_path, save_path+\"validation/\", validation)\n",
    "save_files(data_path, save_path+\"train/\", train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BgManager():\n",
    "    detectron_map = {}\n",
    "\n",
    "    def add_image(self, image_name, nobg_image):\n",
    "        self.detectron_map[image_name] = nobg_image\n",
    "\n",
    "    def get_image(self, image_name):\n",
    "        if image_name in self.detectron_map.keys():\n",
    "            return self.detectron_map.get(image_name)\n",
    "        else: \n",
    "            return 'empty' \n",
    "\n",
    "    def get_img_no_bg(self, predictor, image):\n",
    "        pred = predictor(image)\n",
    "        mask = pred[\"instances\"].pred_masks\n",
    "        if (len(mask) == 0):\n",
    "            return 'empty'\n",
    "        i = len(mask[0][0])\n",
    "        j = len(mask[0])\n",
    "        test = image\n",
    "        for j1 in range(j):\n",
    "            for i1 in range(i):\n",
    "                if (pred[\"instances\"].pred_masks[0][j1][i1] == False):\n",
    "                    test[j1,i1] = 2\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_path =  r\"C:/Users/tala1/Skrivebord/deeplearning/deeplearning-final-project/splitted_data/validation/\"\n",
    "train_path = r\"C:/Users/tala1/Skrivebord/deeplearning/deeplearning-final-project/splitted_data/train/\"\n",
    "test_path =r\"C:/Users/tala1/Skrivebord/deeplearning/deeplearning-final-project/splitted_data/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        RandomHorizontalFlip(p=0.5),\n",
    "        RandomPerspective(distortion_scale=0.3, p=0.4),\n",
    "        transforms.RandomApply(transforms=[\n",
    "            RandomResizedCrop(size=(256, 256), scale=(0.40, 1.0)),\n",
    "        ], p=0.4),\n",
    "  #      transforms.RandomApply(transforms=[\n",
    "  #          GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
    "  #      ], p=0.2),\n",
    "        transforms.RandomErasing(p=0.2), \n",
    "        transforms.RandomRotation(degrees=(-10, 10)), \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trained with this data:\n",
    "\n",
    "  # def __init__(self, imgs_dir, seed=42, num_opel=-1, num_door=-1,\n",
    "   #              num_deloitte_aug=-1, num_gan=-1, num_primary_multiple=1, augmentation=None, \n",
    "   #              test=False, predictor=None, bg_manager=None, grayscale=False):\n",
    "\n",
    "train_dataset = CarDataset(train_path, augmentation=transform)\n",
    "validation_dataset = CarDataset(validation_path, num_gan=0, num_deloitte_aug=0, num_opel=0, num_door=0, num_primary_multiple=1)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0, drop_last=True)\n",
    "valid_loader = DataLoader(validation_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    " \n",
    "# We define the model: \n",
    "model = smp.Unet(\n",
    "    encoder_name='timm-resnest200e', # We use the ResNeSt 200 backbone\n",
    "    encoder_weights='imagenet', # The backbone is trained on imagenet\n",
    "    classes=9, # We have 9 classes\n",
    "    activation='softmax2d', # The last activation is a softmax\n",
    "    in_channels=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n"
     ]
    }
   ],
   "source": [
    "def save_logs(train_log, valid_log):\n",
    "    np.save(\"./models/train_log.npy\", train_log)\n",
    "    np.save(\"./models/valid_log.npy\", valid_log)\n",
    "    \n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "criterion = smpLoss.DiceLoss() # The SMP library also contains various loss functions\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=0.0001),\n",
    "])\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "min_score = 1 \n",
    "\n",
    "train_logs = []\n",
    "valid_logs = []\n",
    "\n",
    "EPOCHS = 2\n",
    "for i in range(0, EPOCHS):\n",
    "    print('\\nEpoch: {}'.format(i))\n",
    "    train_log = []\n",
    "    model.train()\n",
    "    for image, mask in train_loader:\n",
    "        image = image.to(DEVICE)\n",
    "        mask = mask.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = model(image)\n",
    "\n",
    "        loss = criterion(pred, mask)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_log.append(loss.item())\n",
    "    \n",
    "    train_mean = np.mean(train_log)\n",
    "    print(\"Training loss: \",train_mean)\n",
    "    train_logs.append(train_mean)\n",
    "\n",
    "    valid_log = []\n",
    "    model.eval()\n",
    "    for image, mask in valid_loader:\n",
    "        image = image.to(DEVICE)\n",
    "        mask = mask.to(DEVICE)   \n",
    "\n",
    "        pred = model(image)\n",
    "\n",
    "        loss = criterion(pred,mask)\n",
    "        valid_log.append(loss.item())\n",
    "\n",
    "    valid_mean = np.mean(valid_log)\n",
    "    print(\"Validation loss: \",valid_mean)\n",
    "    valid_logs.append(valid_mean)\n",
    "\n",
    "    if (min_score > valid_mean):\n",
    "        min_score = valid_mean\n",
    "        torch.save(model.state_dict(), 'best_model_dict.pth')\n",
    "        print(\"Model saved!\")\n",
    "    if i == EPOCHS/2:\n",
    "        optimizer.param_groups[0]['lr'] = 1e-5\n",
    "        print('---- Decreased Learning Rate to 1e-5! ----')\n",
    "\n",
    "save_logs(train_logs, valid_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log = np.load(r'C:/Users/tala1/Skrivebord/deeplearning/deeplearning-final-project/models/train_log.npy')\n",
    "valid_log = np.load(r'C:/Users/tala1/Skrivebord/deeplearning/deeplearning-final-project/models/valid_log.npy')\n",
    " \n",
    "plt.clf()\n",
    "plt.plot(train_log, label=\"Training\")\n",
    "plt.plot(valid_log, label=\"Validation\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Micro Dice Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import dice_score, accuracy\n",
    "\n",
    "def calc_test_metrics(model, test_dataloader):\n",
    "    \n",
    "    dice_scores_macro = []\n",
    "    accuracy_macro =  []\n",
    "    \n",
    "    for i in test_dataloader:\n",
    "        img, mask = i\n",
    "        pr_mask = model.predict(img) # Predict the mask according to the image\n",
    "        pred = pr_mask[0]\n",
    "        truth = mask[0]\n",
    "        \n",
    "        # We go from [9,256,256] -> [256,256] - e.i. onehot encode to integer encode\n",
    "        pred_label = torch.argmax(pred, dim=0)\n",
    "        truth_label = torch.argmax(truth, dim=0)\n",
    "        \n",
    "        truth_flat = truth_label.view(-1) # go from [256,256] -> [256*256]\n",
    "        pred_flat = torch.flatten(pred, start_dim=1) # go from [9,256,256] -> [9,256*256]\n",
    "        pred_flat = pred_flat.permute(1,0) # go from [9,256*256] -> [256*256,9]]\n",
    "\n",
    "        # calculate dice score macro with only present channels\n",
    "        data_dicescore = dice_score(pred_flat, truth_flat, reduction='none', no_fg_score=-1)\n",
    "        masked_dices = torch.masked_select(data_dicescore,data_dicescore.not_equal(-1))\n",
    "        dice_scores_macro.append(masked_dices.mean())\n",
    "        \n",
    "        # calculate accuracy\n",
    "        acc = accuracy(pred_label, truth_label, average='macro', num_classes=9)\n",
    "        accuracy_macro.append(acc)\n",
    "\n",
    "    return np.mean(dice_scores_macro), np.mean(accuracy_macro)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_base_path = r'C:/Users/tala1/Skrivebord/deeplearning/deeplearning-final-project/models'\n",
    "test_dataset = CarDataset(test_path, test=True)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the model to measure performance on the test data: \n",
    "model.eval()\n",
    "dice, accuracy = calc_test_metrics(model, test_dataloader)\n",
    "print(\"Dice Score: \", dice)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(car_img=None, mask=None, predicted=None):\n",
    "    n = 3\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    plt.subplot(1, n, 1)\n",
    "    plt.imshow(np.dstack(car_img))\n",
    "    plt.title(\"Actual image\")\n",
    "    plt.subplot(1, n, 2)\n",
    "    plt.imshow(mask)\n",
    "    plt.title(\"True mask\")\n",
    "    plt.subplot(1, n, 3)\n",
    "    plt.imshow(predicted)\n",
    "    plt.title(\"Model prediction\")\n",
    "    plt.show()\n",
    "    \n",
    "def prep_and_viz(data, model):\n",
    "    img, mask = data\n",
    "\n",
    "    mask = mask.permute(1,2,0)\n",
    "    mask = torch.argmax(mask, dim=2)\n",
    "\n",
    "    pred = model.predict(img.unsqueeze(0))\n",
    "    \n",
    "    pred = pred.squeeze().cpu().permute(1, 2, 0)\n",
    "    pred = torch.argmax(pred, dim=2)\n",
    "\n",
    "    img1 = img.permute(1,2,0)\n",
    "    visualize(img1,mask,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_and_viz(test_dataset[4], model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((test_dataset[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
